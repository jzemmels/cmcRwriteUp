The authors have not addressed the concerns of the initial review and have in some ways doubled down on their positions. The authors have impractical expectations for algorithm research and an incorrect view of the CMC methods. The NIST CMC methods are not a polished finalized approach for 3D surface comparison. They are works in progress. The fact that details of their algorithm change from paper to paper reflect ongoing improvements. It is not realistic for the authors to create a package (cmcR) that will be a perfect implementation of CMC for use in crime labs with actual casework. The method is not finalized yet.

I am confused about the authors expectations and I believe the overall tone is still inappropriate. The authors are criticizing published progress of an ongoing research project. The NIST authors should be encouraged to continue to publish continual improvements to their methods rather than waiting until there is a single final approach. It is more important to get updates as the algorithm is revised, improved, and tested than it is to have a paper about an open-source implementation of this work. The accurate comparison of surface topographies is a very difficult research challenge. Comparison is affected by the firearm type used, ammunition, caliber, etc... The discipline is still far from a simple clean algorithm that works in all situations. The feeling I get is that the authors believe that NIST has such a ‘final algorithm’ but that they are hiding details preventing others from implementing it. Don’t get me wrong, I commend the authors for creating an open-source implementation of the CMC methods; however, (and I could be wrong) I do not believe the creation of an open-source tool merits a peer-reviewed journal paper. It would be a paper if the authors created the open-source tool and used it to answer a research question (as they start to do see the discussion of the five dimension that have a demonstrable impact below).

The authors responded to the initial review by saying that their goal was to “show that our implementation could produce results that are qualitatively similar to published results”. And they say that they achieved this result “we have been able to qualitatively reproduce the results of the original implementations.”. It is therefore confusing that they also state “we assert that we were not able to obtain “all the information [we] needed for the CMC implementation from the published CMC papers.”. I really don’t understand how they both were and were not able to implement the methods. They go on to say “Our implementation, while providing qualitatively similar results to those in published papers on the Fadul and Weller data sets, is based on a large amount of guesswork and lengthy experimentation due to the ambiguity in the original CMC papers.” To me this says that the NIST algorithms have been published in sufficient detail to be reproduced. It is unrealistic to expect that every detail of the algorithm be explicitly specified. For example, the authors seem shocked and upset that they know of no “open-source implementation of the multivariate band-pass Gaussian regression filter used in surface metrology (ISO 16610-71,2014)”. They specifically cite the ISO standard that describes the mathematical method. The math described in the ISO standard is explicitly what is used. As one further example, the authors state “It is a fact that rotating the contents of a 2D array by any angle other than a multiple of 90 degrees requires interpolation of, and therefore a change in, the values of the array. This requires the user to choose the algorithm used to perform the interpolation” but it is unrealistic to expect algorithm papers to describe how they do their rotation. There are several methods for rotation that would have no effect on the CMC score because the CMC method is somewhat “coarse”. The authors would have to use a very non-standard rotation method to affect a correct CMC implementation.

The authors state “While it is clear that the creators of the CMC pipeline have a working implementation, the wider forensic science community only has access to conceptual descriptions of the pipeline and some summary statistics describing its performance.” and “we argue that it is not acceptable in a forensics/legal setting to only provide a conceptual description of an algorithm for which there clearly exists an actual implementation (i.e., a “step by step approach”).” I disagree with this assumption. The NIST authors do not have a working implementation that is sufficient for use by others in the forensic community. Their code is research level and runs far too slowly for use in practice. The CMC methods are not “camera ready algorithms”. They are ideas meant to spur additional research. They are intended to inspire researchers (like the authors) to build off the basic framework, to make changes, and to test on large datasets. NIST developed the conceptual framework for these approaches. It is now up to additional research groups to take the initial results and extend them.

The authors point to a few new figures (13, 14) to demonstrate the correctness of their implementation by reporting a variance ratio. I am not convinced that this is a good way to compare results; why not use a more established method? Boiling the CMC results from an entire dataset down to a single point is insufficient to demonstrate the correctness of their algorithm.

I agree with the authors that no paper is perfect and that there are questions one could ask of the NIST researchers after having read their papers. But I disagree with the overall tone and assumptions made in this manuscript. As the other reviewer suggested, the authors could directly contact NIST (as can anyone). The authors replied that they have since reached out and have obtained additional information. This is how research works.

In conclusion, the manuscript seems to try to cover too many bases (describing reproducible research, criticizing the NIST papers, describing the CMC methods, describing their implementation, assessing the dimensions that have demonstrable impact, and demonstrating that their implementation is qualitatively similar to the NIST papers).  The best part of the paper is the exploration of conditions that have “demonstrable impact on effectiveness”. This is a worthwhile endeavor and I would encourage the authors to drop the description of the NIST method, the attack of the NIST papers (including details like criticism of missing Gaussian filters and missing rotation descriptions) and rather focus on the exploration of these effects (the five dimensions listed) on CMC. It is more common for a research paper to describe the research and then simply mention that their implementation is available open-source.

I do not believe the paper has been sufficiently modified to address the issues preventing publication.
